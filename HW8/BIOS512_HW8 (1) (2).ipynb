{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.3.3"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"77b97eda-a875-49d9-922a-aca98f18d1ea","cell_type":"markdown","source":"# Homework 08\nThis homework is based on the clustering lectures. Check the lecture notes and TA notes - they should help!","metadata":{}},{"id":"f75ac688-c3c4-4916-a858-97104be7e273","cell_type":"markdown","source":"## Question 1\nThis question will walk you through creating your own `kmeans` function.","metadata":{}},{"id":"9eb3eefd-fd8c-4688-8b9e-e2368e56d526","cell_type":"markdown","source":"#### a) What are the steps of `kmeans`?\n**Hint**: There are 4 steps/builder functions that you'll need.","metadata":{}},{"id":"a788070c-7e90-4c6c-95f1-64a34417f3c4","cell_type":"markdown","source":"1. Load data\n2. Assign points to clusters\n3. compute cluster means\n4. iterate, reassign, recompute kmeans","metadata":{}},{"id":"bf8b199b-d1d9-4a55-ad95-9e86ad0655bd","cell_type":"markdown","source":"#### b) Create the builder function for step 1.","metadata":{}},{"id":"6c7d2d0a-f663-4e00-bd90-6ccbafea9e20","cell_type":"raw","source":"df <- read.csv(\"df.csv\")","metadata":{}},{"id":"9e44ddaf-4506-47d0-98fb-09871e08808c","cell_type":"markdown","source":"#### c) Create the builder function for step 2.","metadata":{}},{"id":"4ecfab0c-fea5-40ae-8ad4-d89249aacb32","cell_type":"raw","source":"df$cluster <- sample(c(\"C0\", \"C1\", \"C2\"), nrow(df), replace = TRUE)\n\nlibrary(ggplot2)\nggplot(df, aes(x, y, color = cluster)) +\n  geom_point(size = 2, alpha = 0.7) +\n  coord_equal()","metadata":{}},{"id":"1c8640c6-2d2f-49c3-b7ed-da0d4fb13935","cell_type":"markdown","source":"#### d) Create the builder function for step 3.\n*Hint*: There are two ways to do this part - one is significantly more efficient than the other. You can do either.  ","metadata":{}},{"id":"baf505cd-785e-4783-b5e3-2d034b801fae","cell_type":"raw","source":"centers_df <- df %>%\n  group_by(cluster) %>%\n  summarise(\n    x = mean(x),\n    y = mean(y),\n    .groups = \"drop\"\n  ) %>%\n  arrange(cluster) %>%\n  mutate(label = paste0(\"μ\", row_number() - 1))","metadata":{}},{"id":"2bbea660-9bd2-4dae-9a5c-838f613b0d7c","cell_type":"markdown","source":"#### e) Create the builder function for step 4.","metadata":{}},{"id":"026fb646-fe80-40d3-a231-4ff8514b0221","cell_type":"raw","source":"assign_to_nearest <- function(df_points, centers) {\n  df_points %>%\n    rowwise() %>%\n    mutate(\n      cluster = centers$cluster[which.min(sqrt((x - centers$x)^2 + (y - centers$y)^2))]\n    ) %>%\n    ungroup()\n}\n\ndf_new <- assign_to_nearest(df, centers_df)","metadata":{}},{"id":"f3c86f61-68d2-484a-9c9c-db7f35c8e685","cell_type":"markdown","source":"#### f) Combine them all into your own `kmeans` function.","metadata":{}},{"id":"909c9f73-6cf9-4895-8a26-0d8f9dc90d79","cell_type":"raw","source":"df <- read.csv(\"df.csv\")\n\ndf$cluster <- sample(c(\"C0\", \"C1\", \"C2\"), nrow(df), replace = TRUE)\n\nlibrary(ggplot2)\nggplot(df, aes(x, y, color = cluster)) +\n  geom_point(size = 2, alpha = 0.7) +\n  coord_equal()\n\n\ncenters_df <- df %>%\n  group_by(cluster) %>%\n  summarise(\n    x = mean(x),\n    y = mean(y),\n    .groups = \"drop\"\n  ) %>%\n  arrange(cluster) %>%\n  mutate(label = paste0(\"μ\", row_number() - 1))\n\nassign_to_nearest <- function(df_points, centers) {\n  df_points %>%\n    rowwise() %>%\n    mutate(\n      cluster = centers$cluster[which.min(sqrt((x - centers$x)^2 + (y - centers$y)^2))]\n    ) %>%\n    ungroup()\n}\n\ndf_new <- assign_to_nearest(df, centers_df)","metadata":{}},{"id":"da13180d-3a51-4218-94a0-3f362612f099","cell_type":"markdown","source":"## Question 2\nThis is when we'll test your `kmeans` function.\n#### a) Read in the `voltages_df.csv` data set. ","metadata":{}},{"id":"d691fb22-6260-48ed-92cf-020c4ccc7305","cell_type":"code","source":"voltages <- read.csv(\"voltages_df.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":13},{"id":"1f002a7b-eda1-4d2d-8ef9-3090b563708d","cell_type":"markdown","source":"#### b) Call your `kmeans` function with 3 clusters. Print the results with `results$labels` and `results$means`. ","metadata":{}},{"id":"341346d4-80da-43fd-b1ba-cbe7d5b4346d","cell_type":"code","source":"library(dplyr)\nlibrary(tibble)\n\nlabel_randomly <- function(n_points, n_clusters){\n  sample(((1:n_points) %% n_clusters)+1, n_points, replace=F)\n}\n\nget_cluster_means <- function(data, labels){\n  data %>%\n    mutate(label__ = labels) %>%\n    group_by(label__) %>%\n    summarize(across(everything(), mean), .groups = \"drop\") %>%\n    arrange(label__)\n}\n\nassign_cluster_fast <- function(data, means){\n  data_matrix <- as.matrix(data)\n  means_matrix <- as.matrix(means %>% dplyr::select(-label__))\n  dii <- sort(rep(1:nrow(data), nrow(means)))\n  mii <- rep(1:nrow(means), nrow(data))\n  data_repped <- data_matrix[dii, ]\n  means_repped <- means_matrix[mii, ]\n  diff_squared <- (data_repped - means_repped)^2\n  all_distances <- rowSums(diff_squared)\n  tibble(dii=dii, mii=mii, distance=all_distances) %>%\n    group_by(dii) %>%\n    arrange(distance) %>%\n    filter(row_number()==1) %>%\n    ungroup() %>%\n    arrange(dii) %>%\n    pull(mii)\n}\n\nassign_cluster_slow <- function(data, means){    \n  dii <- 1:nrow(data)\n  cii <- 1:nrow(means)\n  labels <- c()\n  for(point_index in dii){\n    smallest_dist <- Inf\n    smallest_label <- NA\n    for(clus_index in cii){\n      point <- data[point_index, ]\n      clus <- means %>% dplyr::select(-label__) %>% `[`(clus_index, )\n      diff <- point - clus\n      dist <- sum(diff * diff)\n      if(dist < smallest_dist){\n        smallest_dist <- dist\n        smallest_label <- means[clus_index, ]$label__\n      }\n    }\n    labels <- c(labels, smallest_label)\n  }        \n  labels    \n}\n\nkmeans_done <- function(old_means, new_means, eps=1e-6){\n  om <- as.matrix(old_means)\n  nm <- as.matrix(new_means)\n  m <- mean(sqrt(rowSums((om - nm)^2)))\n  if(m < eps) TRUE else FALSE\n}\n\nmykmeans <- function(data, n_clusters, eps=1e-6, max_it = 1000, verbose = FALSE){\n  labels <- label_randomly(nrow(data), n_clusters)\n  old_means <- get_cluster_means(data, labels)\n  done <- FALSE\n  it <- 0\n  while(!done & it < max_it){\n    labels <- assign_cluster_fast(data, old_means)\n    new_means <- get_cluster_means(data, labels)\n    if(kmeans_done(old_means, new_means)){\n      done <- TRUE\n    } else {\n      old_means <- new_means\n      it <- it + 1\n      if(verbose){\n        cat(sprintf(\"%d\\n\", it))\n      }\n    }\n  }\n  list(labels=labels, means=new_means)\n}\n\n\nresults <- mykmeans(voltages, n_clusters = 3)\nprint(results$labels)\nprint(results$means)","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"  [1] 2 3 3 3 3 3 1 1 3 2 2 2 1 2 3 2 2 2 2 2 3 3 3 3 3 2 2 2 1 1 1 1 3 1 1 3 3\n [38] 2 1 3 2 2 2 1 3 1 1 3 1 1 3 1 2 2 1 2 3 2 1 3 2 2 3 2 1 1 3 1 2 1 2 3 1 1\n [75] 3 3 2 1 1 1 1 1 3 1 1 3 3 3 2 1 1 1 3 1 3 3 1 3 3 1 1 1 3 1 2 2 1 2 2 3 2\n[112] 2 3 1 2 1 2 2 3 3 3 3 2 2 1 3 3 1 2 1 3 2 3 1 2 3 3 3 2 1 2 3 3 1 2 2 3 2\n[149] 2 1 2 1 3 3 1 2 1 1 3 2 1 1 2 3 2 1 3 2 3 2 2 1 3 2 1 1 3 1 2 3 1 3 1 2 1\n[186] 3 3 2 3 2 2 3 2 2 1 1 2 3 2 2 1 2 1 1 3 2 3 1 3 2 3 1 2 1 1 3 1 1 3 3 3 3\n[223] 3 3 3 1 1 1 1 2 3 2 1 3 3 1 1 2 2 1 1 2 1 1 3 1 2 1 1 3 1 3 2 1 3 1 1 2 2\n[260] 2 3 3 1 2 3 3 3 1 1 1 2 3 3 3 1 2 1 1 3 3 1 2 1 2 2 3 1 3 3 1 1 2 1 1 2 3\n[297] 2 1 1 3 3 1 2 2 2 1 2 3 3 3 2 2 2 2 2 2 3 2 3 2 2 1 3 1 2 2 2 2 3 2 3 2 1\n[334] 2 3 3 1 1 2 3 1 3 1 1 2 1 3 1 2 2 1 3 3 3 2 1 3 2 1 1 3 3 3 3 2 1 2 3 2 2\n[371] 2 2 2 3 3 1 1 2 2 2 2 1 1 2 2 1 1 3 3 1 2 3 3 3 3 1 3 3 1 2 2 2 2 3 3 2 2\n[408] 1 1 1 3 1 1 2 3 3 3 1 3 3 3 2 2 3 2 1 3 3 3 3 1 1 3 1 2 3 2 2 2 1 1 1 1 2\n[445] 3 2 2 2 1 3 2 2 2 3 3 2 3 3 2 1 3 3 2 1 3 3 3 2 1 1 2 1 2 3 3 1 2 1 2 3 3\n[482] 1 2 1 1 1 3 1 1 1 1 1 3 2 2 1 1 2 3 3 3 2 2 2 3 3 1 1 2 1 2 3 3 1 1 2 1 1\n[519] 3 2 2 2 3 1 2 3 1 1 2 3 1 1 1 1 2 2 3 2 2 3 3 3 3 1 2 2 1 2 2 2 3 3 2 3 1\n[556] 1 3 1 1 1 3 1 1 3 1 1 3 1 1 2 1 3 1 3 1 3 3 3 2 1 1 1 1 2 3 1 1 1 3 1 1 3\n[593] 3 3 1 2 3 3 2 3 1 3 3 1 2 2 1 1 1 3 1 2 3 2 1 3 2 3 3 2 1 3 2 1 1 2 3 2 1\n[630] 3 2 1 2 3 3 2 3 2 2 2 2 2 3 3 2 1 2 1 1 2 1 3 1 2 1 2 2 2 3 2 2 3 3 2 2 3\n[667] 2 3 1 1 3 2 3 2 2 1 3 3 2 1 2 3 1 1 2 2 3 2 3 3 1 1 1 1 3 3 3 2 1 3 2 1 1\n[704] 2 2 1 3 1 1 2 3 2 1 3 2 3 3 2 3 3 2 2 3 3 2 3 1 2 2 2 2 2 3 3 2 2 3 3 2 3\n[741] 2 3 1 2 2 2 3 2 1 3 3 2 2 1 2 2 1 2 1 1 2 2 3 1 2 3 1 3 3 2 1 3 1 2 3 2 2\n[778] 1 2 1 3 2 2 3 1 3 2 3 2 1 2 2 3 3 3 2 3 2 1 3 3 3 3 2 2 1 3 2 2 2 2 1 1 2\n[815] 1 2 3 2 3 1 3 3 3 3 3 1 1 3 1 1 1 1 1 1 3 2 2 3 1 1 2 3 1 1 1 1 2 2 3 1 3\n[852] 2 1 1 1 1 2 2 1 1 1 1 1 2 3 1 3 2 3 3 1 2 1 1 2 2 3 2 2 2 1 3 1 3 3 2 2 1\n[889] 1 3 2 1 1 3 3 3 3 2 1 1\n\u001b[90m# A tibble: 3 × 251\u001b[39m\n  label__    X0 X1.00401606425703 X2.00803212851406 X3.01204819277108\n    \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n\u001b[90m1\u001b[39m       1 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m             1.31              1.16              0.979\n\u001b[90m2\u001b[39m       2 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m             0.938             0.762             0.363\n\u001b[90m3\u001b[39m       3 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m             1.24              1.09              0.900\n\u001b[90m# ℹ 246 more variables: X4.01606425702811 <dbl>, X5.02008032128514 <dbl>,\u001b[39m\n\u001b[90m#   X6.02409638554217 <dbl>, X7.0281124497992 <dbl>, X8.03212851405623 <dbl>,\u001b[39m\n\u001b[90m#   X9.03614457831325 <dbl>, X10.0401606425703 <dbl>, X11.0441767068273 <dbl>,\u001b[39m\n\u001b[90m#   X12.0481927710843 <dbl>, X13.0522088353414 <dbl>, X14.0562248995984 <dbl>,\u001b[39m\n\u001b[90m#   X15.0602409638554 <dbl>, X16.0642570281125 <dbl>, X17.0682730923695 <dbl>,\u001b[39m\n\u001b[90m#   X18.0722891566265 <dbl>, X19.0763052208835 <dbl>, X20.0803212851406 <dbl>,\u001b[39m\n\u001b[90m#   X21.0843373493976 <dbl>, X22.0883534136546 <dbl>, …\u001b[39m\n"}],"execution_count":16},{"id":"03d9949c-60ce-4a75-8688-e3c7485122ab","cell_type":"markdown","source":"#### c) Call R's `kmeans` function with 3 clusters. Print the results with `results$labels` and `results$cluster`. \n*Hint*: Use the `as.matrix()` function to make the `voltages_df` data frame a matrix before calling `kmeans()`.","metadata":{}},{"id":"3e9d20b8-0af7-403c-9797-8a00da3e1730","cell_type":"code","source":"voltage_matrix <- as.matrix(voltages)\n\nresults <- kmeans(voltage_matrix, centers = 3)\n\nprint(results$cluster)\nprint(results$centers)","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"  [1] 3 2 2 2 2 1 3 3 2 3 3 3 3 3 2 3 3 3 3 3 1 2 2 2 2 3 3 3 3 3 3 3 2 3 3 2 2\n [38] 3 3 1 3 3 3 3 1 3 3 2 3 3 1 3 3 3 3 3 1 3 3 2 3 3 2 3 3 3 1 3 3 3 3 2 3 3\n [75] 2 1 3 3 3 3 3 3 2 3 3 2 2 2 3 3 3 3 2 3 2 1 3 2 2 3 3 3 2 3 3 3 3 3 3 1 3\n[112] 3 1 3 3 3 3 3 2 2 1 2 3 3 3 1 2 3 3 3 2 3 2 3 3 1 2 1 3 3 3 2 2 3 3 3 2 3\n[149] 3 3 3 3 2 2 3 3 3 3 1 3 3 3 3 2 3 3 2 3 2 3 3 3 2 3 3 3 2 3 3 1 3 2 3 3 3\n[186] 1 1 3 1 3 3 1 3 3 3 3 3 1 3 3 3 3 3 3 2 3 2 3 1 3 1 3 3 3 3 2 3 3 2 2 2 1\n[223] 2 2 1 3 3 3 3 3 2 3 3 2 2 3 3 3 3 3 3 3 3 3 2 3 3 3 3 1 3 2 3 3 1 3 3 3 3\n[260] 3 2 2 3 3 2 2 2 3 3 3 3 1 1 1 3 3 3 3 1 2 3 3 3 3 3 1 3 2 2 3 3 3 3 3 3 1\n[297] 3 3 3 2 2 3 3 3 3 3 3 1 2 1 3 3 3 3 3 3 2 3 2 3 3 3 2 3 3 3 3 3 2 3 1 3 3\n[334] 3 1 2 3 3 3 2 3 2 3 3 3 3 2 3 3 3 3 2 1 2 3 3 2 3 3 3 1 2 2 2 3 3 3 1 3 3\n[371] 3 3 3 2 1 3 3 3 3 3 3 3 3 3 3 3 3 1 2 3 3 2 2 1 2 3 1 2 3 3 3 3 3 2 2 3 3\n[408] 3 3 3 2 3 3 3 2 1 1 3 2 2 2 3 3 1 3 3 2 1 2 1 3 3 1 3 3 1 3 3 3 3 3 3 3 3\n[445] 2 3 3 3 3 2 3 3 3 1 2 3 2 2 3 3 2 2 3 3 2 2 2 3 3 3 3 3 3 2 2 3 3 3 3 2 2\n[482] 3 3 3 3 3 2 3 3 3 3 3 2 3 3 3 3 3 2 2 2 3 3 3 2 2 3 3 3 3 3 2 1 3 3 3 3 3\n[519] 2 3 3 3 1 3 3 1 3 3 3 2 3 3 3 3 3 3 2 3 3 2 2 2 1 3 3 3 3 3 3 3 1 2 3 2 3\n[556] 3 2 3 3 3 2 3 3 2 3 3 2 3 3 3 3 1 3 2 3 1 1 2 3 3 3 3 3 3 2 3 3 3 2 3 3 2\n[593] 2 1 3 3 2 2 3 2 3 2 1 3 3 3 3 3 3 1 3 3 1 3 3 2 3 2 2 3 3 2 3 3 3 3 2 3 3\n[630] 1 3 3 3 1 2 3 2 3 3 3 3 3 1 1 3 3 3 3 3 3 3 1 3 3 3 3 3 3 2 3 3 2 2 3 3 2\n[667] 3 1 3 3 2 3 2 3 3 3 1 2 3 3 3 2 3 3 3 3 2 3 1 2 3 3 3 3 2 1 1 3 3 2 3 3 3\n[704] 3 3 3 2 3 3 3 1 3 3 2 3 1 2 3 2 2 3 3 2 1 3 1 3 3 3 3 3 3 2 2 3 3 2 2 3 1\n[741] 3 1 3 3 3 3 2 3 3 2 1 3 3 3 3 3 3 3 3 3 3 3 2 3 3 1 3 1 2 3 3 2 3 3 1 3 3\n[778] 3 3 3 2 3 3 2 3 1 3 1 3 3 3 3 2 2 2 3 2 3 3 2 2 2 2 3 3 3 1 3 3 3 3 3 3 3\n[815] 3 3 1 3 2 3 1 2 2 2 2 3 3 2 3 3 3 3 3 3 2 3 3 2 3 3 3 2 3 3 3 3 3 3 2 3 2\n[852] 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 2 3 1 2 3 3 3 3 3 3 2 3 3 3 3 1 3 2 2 3 3 3\n[889] 3 2 3 3 3 2 2 2 2 3 3 3\n         X0 X1.00401606425703 X2.00803212851406 X3.01204819277108\n1 -1.031463          1.245873         1.0950402         0.9049394\n2 -1.031463          1.243124         1.0913149         0.8984242\n3 -1.031463          1.123724         0.9618318         0.6709520\n  X4.01606425702811 X5.02008032128514 X6.02409638554217 X7.0281124497992\n1         0.3511373         -1.160528         -1.110436        -1.069043\n2         0.2787287         -1.159348         -1.109533        -1.068326\n3        -0.2348958         -1.109877         -1.048146        -0.964286\n  X8.03212851405623 X9.03614457831325 X10.0401606425703 X11.0441767068273\n1        -1.0343093        -1.0027217        -0.9705836       -0.93519388\n2        -1.0336653        -1.0020231        -0.9697003       -0.93399945\n3        -0.8417775        -0.7449379        -0.5477344       -0.07723852\n  X12.0481927710843 X13.0522088353414 X14.0562248995984 X15.0602409638554\n1       -0.89548682        -0.8522194        -0.8079892        -0.7671976\n2       -0.89385445        -0.8500225        -0.8051168        -0.7636351\n3        0.03795671         0.1033652        -0.1775692        -0.2028226\n  X16.0642570281125 X17.0682730923695 X18.0722891566265 X19.0763052208835\n1        -0.7356490        -0.7184454        -0.7161193        -0.7231093\n2        -0.7317237        -0.7153140        -0.7152378        -0.7228370\n3        -0.4467330        -0.9255488        -0.9929924        -0.9628079\n  X20.0803212851406 X21.0843373493976 X22.0883534136546 X23.0923694779116\n1        -0.7319168        -0.7408835        -0.7486848        -0.7545907\n2        -0.7327732        -0.7425159        -0.7508725        -0.7572732\n3        -0.9256890        -0.8930918        -0.8629138        -0.8302993\n  X24.0963855421687 X25.1004016064257 X26.1044176706827 X27.1084337349398\n1        -0.7583186        -0.7599498        -0.7599961       -0.75928422\n2        -0.7614730        -0.7635672        -0.7640633       -0.76375787\n3        -0.7820849        -0.6223898        -0.1490071        0.04858315\n  X28.1124497991968 X29.1164658634538 X30.1204819277108 X31.1244979919679\n1       -0.75846696        -0.7572927        -0.7541178        -0.7460515\n2       -0.76325735        -0.7622897        -0.7592482        -0.7513164\n3       -0.02904835        -0.4780363        -0.4865584        -0.1165327\n  X32.1285140562249 X33.1325301204819 X34.136546184739 X35.140562248996\n1       -0.72955517        -0.7008369       -0.6544317       -0.4872291\n2       -0.73501097        -0.7064079       -0.6525963       -0.4932954\n3       -0.06235668        -0.3217896       -0.8803266       -0.9704336\n  X36.144578313253 X37.1485943775101 X38.1526104417671 X39.1566265060241\n1       0.03396238         0.4863937         0.5379486       -0.05735043\n2      -0.03390026         0.3772924         0.4406407       -0.09479697\n3      -0.92626689        -0.8770299        -0.8301983       -0.78933660\n  X40.1606425702811 X41.1646586345382 X42.1686746987952 X43.1726907630522\n1        -0.6683566        -0.9242637        -0.9502679        -0.8532296\n2        -0.6518143        -0.9039474        -0.8765867        -0.6841762\n3        -0.7606095        -0.7481990        -0.7556403        -0.7739032\n  X44.1767068273092 X45.1807228915663 X46.1847389558233 X47.1887550200803\n1        -0.7315426        -0.5476880        -0.1892358         0.4063077\n2        -0.5540286        -0.3958403        -0.2032288         0.2905789\n3        -0.7946469        -0.8108161        -0.8220337        -0.8279381\n  X48.1927710843374 X49.1967871485944 X50.2008032128514 X51.2048192771084\n1         0.5753620         0.2704433        -0.5260020        -0.9128389\n2         0.4022096         0.0966771        -0.6131835        -0.9277620\n3        -0.8293054        -0.8270369        -0.8214857        -0.8128255\n  X52.2088353413655 X53.2128514056225 X54.2168674698795 X55.2208835341365\n1        -1.0353220        -1.0004920        -0.9676514        -0.9380902\n2        -1.0058768        -0.9725550        -0.9449534        -0.9199306\n3        -0.8019307        -0.7861022        -0.7897399        -0.8075403\n  X56.2248995983936 X57.2289156626506 X58.2329317269076 X59.2369477911647\n1        -0.9064350        -0.8678828        -0.8188867        -0.7571809\n2        -0.8917708        -0.8556405        -0.8079256        -0.7417183\n3        -0.8329051        -0.8449075        -0.8448539        -0.8358612\n  X60.2409638554217 X61.2449799196787 X62.2489959839357 X63.2530120481928\n1        -0.6675043        -0.5059115        -0.1764873        -0.2226683\n2        -0.6360597        -0.4537170        -0.2111698        -0.3013674\n3        -0.8199875        -0.7975540        -0.7676344        -0.7102217\n  X64.2570281124498 X65.2610441767068 X66.2650602409639 X67.2690763052209\n1        -0.5325646        -0.9009078        -0.9146840        -0.9222848\n2        -0.6126171        -0.8768442        -0.9023664        -0.9119603\n3        -0.4358938        -0.1944941        -0.2300542        -0.6559918\n  X68.2730923694779 X69.2771084337349 X70.281124497992 X71.285140562249\n1        -0.9197294        -0.9031742       -0.8688966       -0.8124386\n2        -0.9109706        -0.8956255       -0.8623018       -0.8067408\n3        -0.9393542        -0.9373604       -0.9126939       -0.8838885\n  X72.289156626506 X73.2931726907631 X74.2971887550201 X75.3012048192771\n1       -0.7219536        -0.3487917         0.5214857         0.8316355\n2       -0.7192026        -0.4035692         0.5145391         0.8511776\n3       -0.8499500        -0.8091960        -0.7576007        -0.6716407\n  X76.3052208835341 X77.3092369477912 X78.3132530120482 X79.3172690763052\n1         0.5961856        -0.5660317        -1.0475440        -1.0762565\n2         0.6353941        -0.6097231        -1.0689986        -1.0706910\n3        -0.5862742        -0.5737616        -0.6442067        -0.7211829\n  X80.3212851405623 X81.3253012048193 X82.3293172690763 X83.3333333333333\n1        -1.0350857        -0.9951377        -0.9528293        -0.9068395\n2        -1.0358469        -0.9955586        -0.9528177        -0.9062428\n3        -0.7694646        -0.8233452        -0.8529900        -0.8690791\n  X84.3373493975904 X85.3413654618474 X86.3453815261044 X87.3493975903614\n1        -0.8591647        -0.8156777        -0.7852523        -0.7744626\n2        -0.8577832        -0.8133310        -0.7819655        -0.7706523\n3        -0.8711851        -0.8570312        -0.8241347        -0.7632620\n  X88.3534136546185 X89.3574297188755 X90.3614457831325 X91.3654618473896\n1        -0.7795446        -0.7892668       -0.79436018       -0.78991460\n2        -0.7758953        -0.7862636       -0.79216160       -0.78859823\n3        -0.4049884         0.1162786        0.06886896       -0.02812817\n  X92.3694779116466 X93.3734939759036 X94.3775100401606 X95.3815261044177\n1        -0.7744671        -0.7493130        -0.7184589        -0.6890976\n2        -0.7741497        -0.7501763        -0.7206870        -0.6922182\n3        -0.7480799        -0.9334328        -0.8894283        -0.8410618\n  X96.3855421686747 X97.3895582329317 X98.3935742971888 X99.3975903614458\n1        -0.6720140        -0.6749246        -0.6831933        -0.6861569\n2        -0.6575499        -0.6494302        -0.6611775        -0.6967990\n3        -0.7833918        -0.6996491        -0.6694463        -0.7252025\n  X100.401606425703 X101.40562248996 X102.409638554217 X103.413654618474\n1        -0.6817801       -0.6685226        -0.6452757        -0.5987415\n2        -0.6936421       -0.6788217        -0.6538224        -0.5813017\n3        -0.8093694       -0.8269012        -0.7987492        -0.7618758\n  X104.417670682731 X105.421686746988 X106.425702811245 X107.429718875502\n1        -0.4646349        -0.3949862        -0.3405025        -0.4965818\n2        -0.5072216        -0.3964226        -0.4295125        -0.4777784\n3        -0.7163622        -0.5956578        -0.3465539        -0.2467079\n  X108.433734939759 X109.437751004016 X110.441767068273 X111.44578313253\n1        -0.5930333        -0.7187057        -0.7293524       -0.7452987\n2        -0.6076351        -0.6631021        -0.6881479       -0.7115661\n3        -0.3514577        -0.6685083        -0.8390651       -0.9067344\n  X112.449799196787 X113.453815261044 X114.457831325301 X115.461847389558\n1        -0.7674323        -0.7912740        -0.8116082        -0.8232703\n2        -0.7546820        -0.7939389        -0.8135252        -0.8244461\n3        -0.9126229        -0.8833304        -0.8529353        -0.8289895\n  X116.465863453815 X117.469879518072 X118.473895582329 X119.477911646586\n1        -0.8219775        -0.8049175        -0.7710062        -0.7211318\n2        -0.8224748        -0.8048333        -0.7704493        -0.7201484\n3        -0.8157271        -0.8113318        -0.8079955        -0.7987436\n  X120.481927710843 X121.4859437751 X122.489959839357 X123.493975903614\n1        -0.6574683      -0.4904609        -0.4055303        -0.4741740\n2        -0.6498545      -0.4705406        -0.4093369        -0.5208741\n3        -0.7779420      -0.7176081        -0.5344082        -0.3767216\n  X124.497991967871 X125.502008032129 X126.506024096386 X127.510040160643\n1        -0.7558321        -0.8434514        -0.8569072        -0.8590319\n2        -0.7687459        -0.8391254        -0.8537355        -0.8567804\n3        -0.4080326        -0.6672944        -0.8173464        -0.8236658\n  X128.5140562249 X129.518072289157 X130.522088353414 X131.526104417671\n1      -0.8481258        -0.8244672        -0.7910987        -0.7552432\n2      -0.8466009        -0.8234991        -0.7905217        -0.7548637\n3      -0.7974207        -0.7818738        -0.7918563        -0.8268653\n  X132.530120481928 X133.534136546185 X134.538152610442 X135.542168674699\n1        -0.7300144        -0.7300478        -0.7529338        -0.7847499\n2        -0.7296652        -0.7298068        -0.7529217        -0.7849602\n3        -0.8468949        -0.8514986        -0.8468881        -0.8369852\n  X136.546184738956 X137.550200803213 X138.55421686747 X139.558232931727\n1        -0.8162638        -0.8420555       -0.8589168        -0.8649668\n2        -0.8166912        -0.8427551       -0.8599653        -0.8664522\n3        -0.8251047        -0.8162507       -0.8148012        -0.8207585\n  X140.562248995984 X141.566265060241 X142.570281124498 X143.574297188755\n1        -0.8592897        -0.8418901        -0.8138737        -0.7778305\n2        -0.8613136        -0.8445748        -0.8173783        -0.7824310\n3        -0.8297649        -0.8368127        -0.8381727        -0.8314668\n  X144.578313253012 X145.582329317269 X146.586345381526 X147.590361445783\n1        -0.7351959        -0.6920751        -0.6830996        -0.7065387\n2        -0.7448509        -0.7133705        -0.6932970        -0.7056653\n3        -0.8153693        -0.7891712        -0.7513773        -0.6514404\n  X148.59437751004 X149.598393574297 X150.602409638554 X151.606425702811\n1       -0.7431810        -0.7690228        -0.7927978        -0.8115780\n2       -0.7311370        -0.7656347        -0.7891893        -0.8076282\n3       -0.3711292        -0.2622727        -0.4114979        -0.8144104\n  X152.610441767068 X153.614457831325 X154.618473895582 X155.622489959839\n1        -0.8233287        -0.8263045        -0.8185101        -0.7970554\n2        -0.8189244        -0.8213302        -0.8128264        -0.7904292\n3        -0.8938624        -0.8809273        -0.8639022        -0.8423110\n  X156.626506024096 X157.630522088353 X158.63453815261 X159.638554216867\n1        -0.7568425        -0.6841579       -0.4045481         0.8608342\n2        -0.7486963        -0.6719614       -0.2622993         0.8724486\n3        -0.8170984        -0.7890960       -0.7647990        -0.7490877\n  X160.642570281125 X161.646586345382 X162.650602409639 X163.654618473896\n1         0.9767348         0.7849250         0.0177153        -1.1126259\n2         0.9639645         0.7738459        -0.1120672        -1.1033158\n3        -0.7409729        -0.7383667        -0.7381180        -0.7421149\n  X164.658634538153 X165.66265060241 X166.666666666667 X167.670682730924\n1        -1.0395889       -0.9734278        -0.9246694        -0.8948221\n2        -1.0317032       -0.9659392        -0.9180833        -0.8896277\n3        -0.7485001       -0.7554490        -0.7608708        -0.7619082\n  X168.674698795181 X169.678714859438 X170.682730923695 X171.686746987952\n1        -0.8810906        -0.8775295        -0.8778998        -0.8775001\n2        -0.8773749        -0.8749391        -0.8759741        -0.8758909\n3        -0.7544262        -0.7298647        -0.5699833        -0.1079854\n  X172.690763052209 X173.694779116466 X174.698795180723 X175.70281124498\n1       -0.87336513       -0.86384007        -0.8482374       -0.8267569\n2       -0.87185869       -0.86231396        -0.8466172       -0.8249829\n3        0.04722782       -0.05957484        -0.5838129       -0.8882710\n  X176.706827309237 X177.710843373494 X178.714859437751 X179.718875502008\n1        -0.8006644        -0.7727126        -0.7476321        -0.7318663\n2        -0.7986672        -0.7704058        -0.7449922        -0.7294294\n3        -0.8539757        -0.7695053        -0.6816092        -0.6408262\n  X180.722891566265 X181.726907630522 X182.730923694779 X183.734939759036\n1        -0.7304600        -0.7419756        -0.7601631        -0.7791711\n2        -0.7290907        -0.7409448        -0.7589050        -0.7774115\n3        -0.6913369        -0.7711124        -0.8108296        -0.8302308\n  X184.738955823293 X185.74297188755 X186.746987951807 X187.751004016064\n1        -0.7949314       -0.8050083        -0.8084081        -0.8056017\n2        -0.7924914       -0.8016969        -0.8039880        -0.7997962\n3        -0.8457154       -0.8548781        -0.8566039        -0.8504474\n  X188.755020080321 X189.759036144578 X190.763052208835 X191.767068273092\n1        -0.7986982        -0.7915701        -0.7893827        -0.7967554\n2        -0.7912509        -0.7823894        -0.7787544        -0.7854155\n3        -0.8361850        -0.8133510        -0.7802598        -0.7256342\n  X192.771084337349 X193.775100401606 X194.779116465863 X195.78313253012\n1        -0.8151266       -0.84200184        -0.8727333      -0.90241396\n2        -0.8039523       -0.83163810        -0.8635567      -0.89466724\n3        -0.4480129        0.07077084         0.0626212      -0.08014399\n  X196.787148594378 X197.791164658635 X198.795180722892 X199.799196787149\n1        -0.9267372        -0.9422645        -0.9465001        -0.9378980\n2        -0.9206485        -0.9381266        -0.9447397        -0.9391553\n3        -0.7790090        -0.9608427        -0.9279956        -0.8988733\n  X200.803212851406 X201.807228915663 X202.81124497992 X203.815261044177\n1        -0.9158071        -0.8803477       -0.8321912        -0.7721660\n2        -0.9210513        -0.8910695       -0.8507494        -0.8024970\n3        -0.8744666        -0.8548905       -0.8388328        -0.8236099\n  X204.819277108434 X205.823293172691 X206.827309236948 X207.831325301205\n1        -0.7002076        -0.6067468        -0.1098143         0.4207671\n2        -0.7496946        -0.6971333        -0.6519524        -0.6236966\n3        -0.8061180        -0.7834938        -0.7412057        -0.6397551\n  X208.835341365462 X209.839357429719 X210.843373493976 X211.847389558233\n1         0.7957051         0.2152144        -0.4380059       -0.93524522\n2        -0.6189740        -0.6126166        -0.5514026        0.07756414\n3        -0.4576918        -0.4139470        -0.5455483       -0.75742800\n  X212.85140562249 X213.855421686747 X214.859437751004 X215.863453815261\n1       -0.9411393        -0.8821014        -0.7003658         0.2202006\n2        0.8988625         0.8884011         0.5531202        -0.5322118\n3       -0.8068612        -0.7660377        -0.7096709        -0.6431906\n  X216.867469879518 X217.871485943775 X218.875502008032 X219.879518072289\n1         0.9652767         0.9326633         0.7176057        -0.4727933\n2        -1.0160084        -0.9386326        -0.7992775        -0.5128268\n3        -0.6213680        -0.6449897        -0.6996839        -0.7247352\n  X220.883534136546 X221.887550200803 X222.89156626506 X223.895582329317\n1        -1.0462411       -1.05011565       -1.0079484        -0.9837001\n2        -0.1621612       -0.09738382       -0.4612028        -0.8843154\n3        -0.7348560       -0.73582125       -0.7289767        -0.7152091\n  X224.899598393574 X225.903614457831 X226.907630522088 X227.911646586345\n1        -0.9738671        -0.9725299        -0.9735992       -0.97239260\n2        -0.9501220        -0.9614418        -0.9689313       -0.97078084\n3        -0.6877745        -0.5605799        -0.2054143       -0.07317932\n  X228.915662650602 X229.919678714859 X230.923694779116 X231.927710843374\n1        -0.9662790        -0.9548617        -0.9399930        -0.9254512\n2        -0.9660888        -0.9553815        -0.9409694        -0.9268295\n3        -0.2221838        -0.7314874        -0.9252416        -0.9229558\n  X232.931726907631 X233.935742971888 X234.939759036145 X235.943775100402\n1        -0.9158243        -0.9144223        -0.9212453        -0.9328464\n2        -0.9175849        -0.9164864        -0.9234823        -0.9351429\n3        -0.9033189        -0.8832138        -0.8616690        -0.8378087\n  X236.947791164659 X237.951807228916 X238.955823293173 X239.95983935743\n1        -0.9441382        -0.9503261        -0.9478582       -0.9345562\n2        -0.9464305        -0.9525853        -0.9500650       -0.9366832\n3        -0.8111274        -0.7808217        -0.7419944       -0.6216227\n  X240.963855421687 X241.967871485944 X242.971887550201 X243.975903614458\n1        -0.9093694       -0.87200867       -0.82253175        -0.7606134\n2        -0.9113662       -0.87377754       -0.82385929        -0.7608566\n3        -0.2268060        0.01333991       -0.05285934        -0.5433274\n  X244.979919678715 X245.983935742972 X246.987951807229 X247.991967871486\n1        -0.6785901        -0.3916473       -0.08367886        0.02967317\n2        -0.6636216        -0.3140227       -0.03042208        0.02754518\n3        -0.9271054        -0.9278647       -0.89463579       -0.86078516\n  X248.995983935743       X250\n1        -0.3416634 -0.7627508\n2        -0.4426584 -0.8335155\n3        -0.8323765 -0.8090319\n"}],"execution_count":4},{"id":"4944ea46-ed01-413b-8b55-d55f383413de","cell_type":"markdown","source":"#### d) Are your labels/clusters the same? If not, why? Are your means the same?","metadata":{}},{"id":"c1fa09df-a939-43c8-810f-260616c9493f","cell_type":"markdown","source":"- The labels and clusters are slightly different because of the manual computation that is being completed with the loops to determine centroids. The means are also slightly different. ","metadata":{}},{"id":"6228e5ce-269f-4d83-b94e-40f3c4a137cd","cell_type":"markdown","source":"## Question 3\n#### a) Explain the process of using a for loop to assign clusters for kmeans.","metadata":{}},{"id":"d3673708-5866-4778-920c-cafc3e34f368","cell_type":"markdown","source":"- For each data point, we loop over all clusters and then compute the distance between the point and each cluster mean such that there is a double loop of N over K.","metadata":{}},{"id":"2815b679-8bd1-4ec2-85d3-e42166f3e0ff","cell_type":"markdown","source":"#### b) Explain the process of vectorizing the code to assign clusters for kmeans.","metadata":{}},{"id":"c6d4b48a-a76a-4e7c-8841-e6b3c090680e","cell_type":"markdown","source":"- Two matrices are created to compare all cluster-points at the same time where the matrices are then subtracted to compute the distances.","metadata":{}},{"id":"c6be7b85-c4f0-4626-b7f5-0ba921efcb6d","cell_type":"markdown","source":"#### c) State which (for loops or vectorizing) is more efficient and why.","metadata":{}},{"id":"5d3378ed-c09e-4827-a92b-adb8865b4fd8","cell_type":"markdown","source":"- Vectorizing is more efficient because index vectors are reptitively created without the use of a loop, which allows more efficiency in developing replicated matrices.","metadata":{}},{"id":"3d2824d8-b8b6-4746-8fdc-8b3a8a1ca49d","cell_type":"markdown","source":"## Question 4\n#### When does `kmeans` fail? What assumption does `kmeans` use that causes it to fail in this situation?","metadata":{}},{"id":"638296c6-89b1-427c-a5ab-c461068e2365","cell_type":"markdown","source":"- kmeans fails when clusters are not the same size or if there is no predefined K number of centers.\n- The assumptions that would cause failure are that the clusters are all spherical and of the same size and a predefined K is set.","metadata":{}},{"id":"20c5a711-449c-48e0-b02b-8ad3346e8d38","cell_type":"markdown","source":"## Question 5\n#### What assumption do Guassian mixture models make?","metadata":{}},{"id":"e21794cb-34a6-4545-a026-7e2cfa970679","cell_type":"markdown","source":"- The assumption is that data is drawn from N Gaussian distributions with individual parameters estimated from the data.","metadata":{}},{"id":"ed1a4f52-f2d5-45d7-aeb2-a05ccab9e2fe","cell_type":"markdown","source":"## Question 6\n#### What assumption does spectral clustering make? Why does this help us?","metadata":{}},{"id":"00876e3d-1a6d-4f77-8e4c-4d58047e9027","cell_type":"markdown","source":"- The assumption is that two points are likely to be in the same cluster if close to one another.\n- This helps us because it is a singular assumption made and is only a metric of the original data that is used.","metadata":{}},{"id":"ede993cf-222f-4c5b-b09e-bc2c988a777e","cell_type":"markdown","source":"## Question 7\n#### Define the gap statistic method. What do we use it for?","metadata":{}},{"id":"c1803cc9-f4df-40c0-a925-fe8ce8be1db9","cell_type":"markdown","source":"- This is comparing the clustering of each value to a cluster of randomized data in the same domain as the original data.\n- We use this for standard comparisons to look at the most basic, best fit model.","metadata":{}},{"id":"2f5768e3-3b1b-45ad-b683-e95ad22a98ed","cell_type":"code","source":"","metadata":{"trusted":false},"outputs":[],"execution_count":null}]}