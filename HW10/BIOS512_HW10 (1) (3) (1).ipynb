{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.3.3"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4d684172-4b94-42cf-bda2-e11952420d86","cell_type":"markdown","source":"# Homework 10\n#### Course Notes\n**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19","metadata":{}},{"id":"d839a5ba-62f4-4699-baea-018afda70786","cell_type":"markdown","source":"## Question 1\n#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified.","metadata":{}},{"id":"9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49","cell_type":"markdown","source":"#### a) Make a function to tokenize the text.","metadata":{}},{"id":"33e1b6fd-dffb-403a-b9e5-504254da2dec","cell_type":"code","source":"tokenize_text <- function(text) {\n    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n}","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"86145513-294b-4894-a02c-8ae60e2c616e","cell_type":"markdown","source":"#### b) Make a function generate keys for ngrams.","metadata":{}},{"id":"66738034-93bf-46ab-a0c1-0a40a8831fe6","cell_type":"code","source":"keys <- function(ngram, sep = \"\\x1f\") {\n    paste(ngram, collapse=sep)\n}","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"52988c2c-b230-467f-b519-72bc85b93b43","cell_type":"markdown","source":"#### c) Make a function to build an ngram table.","metadata":{}},{"id":"a237baab-0de1-4cc4-8a75-9e7bc0a01454","cell_type":"code","source":"build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n    tbl <- new.env(parent = emptyenv())\n    for (i in seq_len(length(tokens) - n + 1L)) {\n        ngram <- tokens[i:(i + n - 2L)]\n        next_word <- tokens[i + n - 1L]\n        key <- paste(ngram, collapse = sep)\n        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n        if (next_word %in% names(counts)) {\n            counts[[next_word]] <- counts[[next_word]] + 1L\n        } else {\n            counts[[next_word]] <- 1L\n        }\n        tbl[[key]] <- counts\n    }\n    tbl\n}","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"1ca6db37-abce-4705-9784-e1b898174f00","cell_type":"markdown","source":"#### d) Function to digest the text.","metadata":{}},{"id":"a34a36d0-13c5-45a4-b0e2-e8d8a08fb6da","cell_type":"code","source":"digest_text <- function(text, n) {\n    tokens <- tokenize_text(text)\n    build_ngram_table(tokens, n)\n}","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"53fff313-0f13-479b-94df-7588c19fdd3d","cell_type":"markdown","source":"#### e) Function to digest the url.","metadata":{}},{"id":"9f62bdc6-2b7b-4af5-b88d-2bddbf0e99fb","cell_type":"code","source":"digest_url <- function(url, n) {\n    res <- httr::GET(url)\n    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n    digest_text(txt,n)\n}","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a","cell_type":"markdown","source":"#### f) Function that gives random start.","metadata":{}},{"id":"c45eccf2-ee7e-482d-9a7f-d6880b912986","cell_type":"code","source":"random_start <- function(tbl, sep = \"\\x1f\") {\n    keys <- ls(envir = tbl, all.names=TRUE)\n    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n    picked <- sample(keys, 1)\n    strsplit(picked, sep, fixed=TRUE)[[1]]\n}","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"e998fb24-f2d6-41bc-a751-1f6accd3411f","cell_type":"markdown","source":"#### g) Function to predict the next word.","metadata":{}},{"id":"bf2b412d-6653-4b9f-aed1-f49aa971bc9c","cell_type":"code","source":"predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n    key <- paste(ngram, collapse = sep)\n    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n    if (length(counts) == 0) return(NA_character_)\n    sample(names(counts), size=1, prob=as.numeric(counts))\n}","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"347f4002-4932-42c4-a4af-8689293a5857","cell_type":"markdown","source":"#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used.","metadata":{}},{"id":"91922850-d3c8-4ec9-8751-4bb3248a8dab","cell_type":"code","source":"make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n    force(tbl); n <- as.integer(n); force(sep)\n    function(start_words = NULL, length = 10L) {\n        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n            start_words <- random_start(tbl, sep=sep)\n        }\n        word_sequence <- start_words\n        for (i in seq_len(max(0L, length - length(start_words)))) {\n            ngram <- tail(word_sequence, n - 1L)\n            next_word <- predict_next_word(tbl, ngram, sep=sep)\n            if (is.na(next_word)) break\n            word_sequence <- c(word_sequence, next_word)\n        }\n        paste(word_sequence, collapse= \" \")\n    }\n}","metadata":{"trusted":false},"outputs":[],"execution_count":null},{"id":"3b742c67-907c-4bc7-8df1-c84fa65a7554","cell_type":"markdown","source":"## Question 2\n#### For this question, set `seed=2025`.\n#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n#### ii) Using n=3, with no start word, with length=15.","metadata":{}},{"id":"78b161f8-a3d8-482a-a3af-16af0b155985","cell_type":"code","source":"library(httr)\nlibrary(tokenizers)\n\nset.seed(2025)\n\ntokenize_text <- function(text) {\n    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n}\n\nkey_from <- function(ngram, sep = \"\\x1f\") {\n    paste(ngram, collapse=sep)\n}\n\nbuild_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n    tbl <- new.env(parent = emptyenv())\n    for (i in seq_len(length(tokens) - n + 1L)) {\n        ngram <- tokens[i:(i + n - 2L)]\n        next_word <- tokens[i + n - 1L]\n        key <- paste(ngram, collapse = sep)\n        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n        if (next_word %in% names(counts)) {\n            counts[[next_word]] <- counts[[next_word]] + 1L\n        } else {\n            counts[[next_word]] <- 1L\n        }\n        tbl[[key]] <- counts\n    }\n    tbl\n}\n\ndigest_text <- function(text, n) {\n    tokens <- tokenize_text(text)\n    build_ngram_table(tokens, n)\n}\n\ndigest_url <- function(url, n) {\n    res <- httr::GET(url)\n    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n    digest_text(txt,n)\n}\n\nrandom_start <- function(tbl, sep = \"\\x1f\") {\n    keys <- ls(envir = tbl, all.names=TRUE)\n    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n    picked <- sample(keys, 1)\n    strsplit(picked, sep, fixed=TRUE)[[1]]\n}\n\npredict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n    key <- paste(ngram, collapse = sep)\n    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n    if (length(counts) == 0) return(NA_character_)\n    sample(names(counts), size=1, prob=as.numeric(counts))\n}\n\nmake_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n    force(tbl); n <- as.integer(n); force(sep)\n    function(start_words = \"the king\", length = 10L) {\n        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n            start_words <- random_start(tbl, sep=sep)\n        }\n        word_sequence <- start_words\n        for (i in seq_len(max(0L, length - length(start_words)))) {\n            ngram <- tail(word_sequence, n - 1L)\n            next_word <- predict_next_word(tbl, ngram, sep=sep)\n            if (is.na(next_word)) break\n            word_sequence <- c(word_sequence, next_word)\n        }\n        paste(word_sequence, collapse= \" \")\n    }\n}\n\n\nurl <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\ntbl3 <- digest_url(url, n=3)\ngen3 <- make_ngram_generator(tbl3, n=3)\nprint(gen3(length=15))","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"[1] \"spread the jam over it spread its wings and crying here comes our hobblety jib\"\n"}],"execution_count":11},{"id":"80d35ca5-ae64-476a-92d5-d76763b05490","cell_type":"code","source":"library(httr)\nlibrary(tokenizers)\n\nset.seed(2025)\n\ntokenize_text <- function(text) {\n    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n}\n\nkey_from <- function(ngram, sep = \"\\x1f\") {\n    paste(ngram, collapse=sep)\n}\n\nbuild_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n    tbl <- new.env(parent = emptyenv())\n    for (i in seq_len(length(tokens) - n + 1L)) {\n        ngram <- tokens[i:(i + n - 2L)]\n        next_word <- tokens[i + n - 1L]\n        key <- paste(ngram, collapse = sep)\n        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n        if (next_word %in% names(counts)) {\n            counts[[next_word]] <- counts[[next_word]] + 1L\n        } else {\n            counts[[next_word]] <- 1L\n        }\n        tbl[[key]] <- counts\n    }\n    tbl\n}\n\ndigest_text <- function(text, n) {\n    tokens <- tokenize_text(text)\n    build_ngram_table(tokens, n)\n}\n\ndigest_url <- function(url, n) {\n    res <- httr::GET(url)\n    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n    digest_text(txt,n)\n}\n\nrandom_start <- function(tbl, sep = \"\\x1f\") {\n    keys <- ls(envir = tbl, all.names=TRUE)\n    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n    picked <- sample(keys, 1)\n    strsplit(picked, sep, fixed=TRUE)[[1]]\n}\n\npredict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n    key <- paste(ngram, collapse = sep)\n    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n    if (length(counts) == 0) return(NA_character_)\n    sample(names(counts), size=1, prob=as.numeric(counts))\n}\n\nmake_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n    force(tbl); n <- as.integer(n); force(sep)\n    function(start_words = NULL, length = 10L) {\n        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n            start_words <- random_start(tbl, sep=sep)\n        }\n        word_sequence <- start_words\n        for (i in seq_len(max(0L, length - length(start_words)))) {\n            ngram <- tail(word_sequence, n - 1L)\n            next_word <- predict_next_word(tbl, ngram, sep=sep)\n            if (is.na(next_word)) break\n            word_sequence <- c(word_sequence, next_word)\n        }\n        paste(word_sequence, collapse= \" \")\n    }\n}\n\n\nurl <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\ntbl3 <- digest_url(url, n=3)\ngen3 <- make_ngram_generator(tbl3, n=3)\nprint(gen3(length=15))","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"[1] \"spread the jam over it spread its wings and crying here comes our hobblety jib\"\n"}],"execution_count":13},{"id":"0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc","cell_type":"markdown","source":"#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n#### ii) Using n=3, with no start word, with length=15.","metadata":{}},{"id":"21f510cf-1c09-4488-9f6f-a5c22bf91e51","cell_type":"code","source":"library(httr)\nlibrary(tokenizers)\n\nset.seed(2025)\n\ntokenize_text <- function(text) {\n    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n}\n\nkey_from <- function(ngram, sep = \"\\x1f\") {\n    paste(ngram, collapse=sep)\n}\n\nbuild_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n    tbl <- new.env(parent = emptyenv())\n    for (i in seq_len(length(tokens) - n + 1L)) {\n        ngram <- tokens[i:(i + n - 2L)]\n        next_word <- tokens[i + n - 1L]\n        key <- paste(ngram, collapse = sep)\n        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n        if (next_word %in% names(counts)) {\n            counts[[next_word]] <- counts[[next_word]] + 1L\n        } else {\n            counts[[next_word]] <- 1L\n        }\n        tbl[[key]] <- counts\n    }\n    tbl\n}\n\ndigest_text <- function(text, n) {\n    tokens <- tokenize_text(text)\n    build_ngram_table(tokens, n)\n}\n\ndigest_url <- function(url, n) {\n    res <- httr::GET(url)\n    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n    digest_text(txt,n)\n}\n\nrandom_start <- function(tbl, sep = \"\\x1f\") {\n    keys <- ls(envir = tbl, all.names=TRUE)\n    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n    picked <- sample(keys, 1)\n    strsplit(picked, sep, fixed=TRUE)[[1]]\n}\n\npredict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n    key <- paste(ngram, collapse = sep)\n    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n    if (length(counts) == 0) return(NA_character_)\n    sample(names(counts), size=1, prob=as.numeric(counts))\n}\n\nmake_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n    force(tbl); n <- as.integer(n); force(sep)\n    function(start_words = \"the king\", length = 10L) {\n        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n            start_words <- random_start(tbl, sep=sep)\n        }\n        word_sequence <- start_words\n        for (i in seq_len(max(0L, length - length(start_words)))) {\n            ngram <- tail(word_sequence, n - 1L)\n            next_word <- predict_next_word(tbl, ngram, sep=sep)\n            if (is.na(next_word)) break\n            word_sequence <- c(word_sequence, next_word)\n        }\n        paste(word_sequence, collapse= \" \")\n    }\n}\n\n\nurl <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\ntbl3 <- digest_url(url, n=3)\ngen3 <- make_ngram_generator(tbl3, n=3)\nprint(gen3(length=15))","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"[1] \"lamentation de lemburn came forth completely armed after the fashion of this may be seen\"\n"}],"execution_count":18},{"id":"5d78d32d-51d3-4667-84db-28eca5a4c080","cell_type":"code","source":"library(httr)\nlibrary(tokenizers)\n\nset.seed(2025)\n\ntokenize_text <- function(text) {\n    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n}\n\nkey_from <- function(ngram, sep = \"\\x1f\") {\n    paste(ngram, collapse=sep)\n}\n\nbuild_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n    tbl <- new.env(parent = emptyenv())\n    for (i in seq_len(length(tokens) - n + 1L)) {\n        ngram <- tokens[i:(i + n - 2L)]\n        next_word <- tokens[i + n - 1L]\n        key <- paste(ngram, collapse = sep)\n        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n        if (next_word %in% names(counts)) {\n            counts[[next_word]] <- counts[[next_word]] + 1L\n        } else {\n            counts[[next_word]] <- 1L\n        }\n        tbl[[key]] <- counts\n    }\n    tbl\n}\n\ndigest_text <- function(text, n) {\n    tokens <- tokenize_text(text)\n    build_ngram_table(tokens, n)\n}\n\ndigest_url <- function(url, n) {\n    res <- httr::GET(url)\n    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n    digest_text(txt,n)\n}\n\nrandom_start <- function(tbl, sep = \"\\x1f\") {\n    keys <- ls(envir = tbl, all.names=TRUE)\n    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n    picked <- sample(keys, 1)\n    strsplit(picked, sep, fixed=TRUE)[[1]]\n}\n\npredict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n    key <- paste(ngram, collapse = sep)\n    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n    if (length(counts) == 0) return(NA_character_)\n    sample(names(counts), size=1, prob=as.numeric(counts))\n}\n\nmake_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n    force(tbl); n <- as.integer(n); force(sep)\n    function(start_words = NULL, length = 10L) {\n        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n            start_words <- random_start(tbl, sep=sep)\n        }\n        word_sequence <- start_words\n        for (i in seq_len(max(0L, length - length(start_words)))) {\n            ngram <- tail(word_sequence, n - 1L)\n            next_word <- predict_next_word(tbl, ngram, sep=sep)\n            if (is.na(next_word)) break\n            word_sequence <- c(word_sequence, next_word)\n        }\n        paste(word_sequence, collapse= \" \")\n    }\n}\n\n\nurl <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\ntbl3 <- digest_url(url, n=3)\ngen3 <- make_ngram_generator(tbl3, n=3)\nprint(gen3(length=15))","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"[1] \"lamentation de lemburn came forth completely armed after the fashion of this may be seen\"\n"}],"execution_count":17},{"id":"25fb37ad-8e7c-4e62-afc0-ba46d46401fc","cell_type":"markdown","source":"#### c) Explain in 1-2 sentences the difference in content generated from each source.","metadata":{}},{"id":"56e45972-f441-4d07-9073-fcddd6146cbd","cell_type":"markdown","source":"## Question 3\n#### a) What is a language learning model? \n#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?","metadata":{}},{"id":"3a3defbc-e7c5-4e4e-b82f-1e848d70e8b8","cell_type":"markdown","source":"a) a language learning model is a probability distribution that is based on words which occurs based on conditioning.","metadata":{}},{"id":"74ce1e55-b6ba-4485-b798-20a30fe9edc7","cell_type":"markdown","source":"b) A language model is run locally by OLLAMA.","metadata":{}},{"id":"b85a743b-f814-4a53-96e6-8bccb3d34ab8","cell_type":"markdown","source":"## Question 4\n#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n| Term | Meaning |  \n|------|---------|\n| **Shell** |  |\n| **Terminal emulator** |  |\n| **Process** |  |\n| **Signal** |  |\n| **Standard input** |  |\n| **Standard output** |  |\n| **Command line argument** |  |\n| **The environment** |  |","metadata":{}},{"id":"1332ff27-ca3f-4f7e-b4b9-07ead0358dd2","cell_type":"markdown","source":"## Question 5\n#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n#### a) What are the programs?\n#### b) Explain what this command is doing, part by part.","metadata":{}},{"id":"69771ac7-865e-4d82-aa25-a39e7c1ab095","cell_type":"markdown","source":"## Question 6\n#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n#### a) Show the response when you run `docker run hello-world`.\n#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n#### c) How do you log in to the RStudio server?","metadata":{}},{"id":"8d7e9ee8-797a-4ada-aa84-3f01975c57d1","cell_type":"markdown","source":"a) Hello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (arm64v8)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/","metadata":{}},{"id":"74973817-5357-4974-9dc6-ec24cfb3e13f","cell_type":"code","source":"b) ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}